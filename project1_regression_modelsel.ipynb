{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "eDY78I8-wXdy",
      "metadata": {
        "id": "eDY78I8-wXdy"
      },
      "source": [
        "# Project 1: Regression and Model Selection\n",
        "\n",
        "In this project, you will construct a linear regression model, and apply it to a synthetic task as well as a real-world house value prediction task.\n",
        "\n",
        "## Objectives\n",
        "Your goal in this project is to get comfortable in implementing a complete supervised learning pipeline (in Python). To complete this project, you should understand the following:\n",
        "\n",
        "* How to use basic math and machine learning modules in python such as numpy, matplotlib, and sklearn (*_You are encouraged to use numpy to vectorize array operations [see link](https://numpy.org/doc/stable//user/absolute_beginners.html#basic-array-operations)_*)\n",
        "* How to train a regression model *from scratch*\n",
        "* How to implement the *gradient descent* algorithm for iterative model update\n",
        "* How to perform model section when facing multiple choices\n",
        "* How to evaluate the test results and visualize the outcome of an ML model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a0af1538",
      "metadata": {},
      "source": [
        "## Deliverable\n",
        "* Project report/writeup: A `project1_report_lastname.pdf` file with corresponding plots and results for the project. Follow the `Project 1 - Report (Individual Submission)` link on Gradescope to upload this file. The project report should include a brief justification of your solution at a high-level, e.g., using any relevant explanations, equations, or pictures that help to explain your solution. You should also describe what your code does, e.g. using a couple of sentences per function to describe your code structure. \n",
        "\n",
        "* Source code: A `project1_src_lastname1[_lastname2].ipynb` (or `.zip`) file with a working copy of your solutions compiled in a Jupyter notebook. Follow the `Project 1 - Source Code (Group Submission)` link to upload this file.\n",
        "\n",
        "\n",
        "## Logistics\n",
        "\n",
        "* You can work in groups of 1-2 students for each course project, and it's your responsibility to find a group (e.g. use Ed Discussion). \n",
        "* Every member of a group must complete and submit the project report/writeup individually. While the source code can be the same for all group members, the project report needs to be written independently by each person and, thus, should differ among team member and students more generally.\n",
        "* One one group member need to submit the source code. If you submit as a group, make sure to include your teammate in the group submission. Instructions for team submission can be found [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members).\n",
        "* Grades will be provided based on the individual project report. The source code submission will not be graded, but the teaching staff may check the source files if they see the need for reproducing your results when going through your project report. \n",
        "* Failure to submit the source code will lead to a deduction of points from your total.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d-5QFRQs8KMZ",
      "metadata": {
        "id": "d-5QFRQs8KMZ"
      },
      "source": [
        "# Task 1A: Linear Regression (50 points + 10 bonus points)\n",
        "\n",
        "## Overview\n",
        "In this task, you will implement linear regression with gradient descent optimization from scratch. You'll work with a synthetic dataset to understand the core concepts of regression and optimization.\n",
        "\n",
        "### Learning Objectives\n",
        "- Implement linear regression without using pre-built ML libraries\n",
        "- Understand gradient descent optimization\n",
        "- Learn to visualize and analyze model performance\n",
        "- Master loss function implementation and optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a132e988",
      "metadata": {},
      "source": [
        "## Problem Setup\n",
        "\n",
        "### Loading Necessary Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KSOkRgRg8vIe",
      "metadata": {
        "id": "KSOkRgRg8vIe"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# General math and plotting modules.\n",
        "import numpy as np                                      # NumPy is a library for numerical operations on large, multi-dimensional arrays and matrices.\n",
        "import matplotlib.pyplot as plt                         # Matplotlib is a plotting library for creating static, animated, and interactive visualizations in Python.\n",
        "from matplotlib.colors import ListedColormap            # ListedColormap is used to create custom colormaps for plotting.\n",
        "\n",
        "# Machine Learning library.\n",
        "from sklearn.model_selection import train_test_split    # train_test_split is a utility function to split data into training and testing sets.\n",
        "from sklearn.preprocessing import StandardScaler        # StandardScaler is used to standardize features by removing the mean and scaling to unit variance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_zC9jNFb_mVJ",
      "metadata": {
        "id": "_zC9jNFb_mVJ"
      },
      "source": [
        "### Utility Functions\n",
        "\n",
        "This section provides utility functions for data generation and visualization. These functions are pre-implemented to help you focus on the core machine learning concepts. You don't need to modify these functions.\n",
        "\n",
        "#### Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9BrgqQPf_ll-",
      "metadata": {
        "id": "9BrgqQPf_ll-"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def generate_polynomial_data(num_points: int, noise: float, w: np.array) -> Tuple[np.array, np.array]:\n",
        "    \"\"\"\n",
        "    Generate synthetic polynomial regression data.\n",
        "    \n",
        "    Args:\n",
        "        num_points (int): Number of data points to generate\n",
        "        noise (float): Standard deviation of Gaussian noise\n",
        "        w (np.array): True polynomial coefficients [w_n, ..., w_1, w_0]\n",
        "                     where n is the polynomial degree\n",
        "    \n",
        "    Returns:\n",
        "        x1 (np.array): Feature matrix of shape (num_points, degree+1)\n",
        "                      Each row is [x^n, ..., x^1, 1]\n",
        "        y (np.array): Target values of shape (num_points,)\n",
        "    \"\"\"\n",
        "    dim = w.size - 1  # Polynomial degree\n",
        "    \n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # Generate base feature values from normal distribution\n",
        "    x = np.random.normal(size=(num_points, 1))\n",
        "    \n",
        "    # Initialize with bias term (x^0 = 1)\n",
        "    x1 = np.power(x, 0)\n",
        "    \n",
        "    # Build polynomial features up to specified degree\n",
        "    for d in range(dim):\n",
        "        # Concatenate new polynomial term to existing features\n",
        "        # Final matrix: [x^n, ..., x^1, 1]\n",
        "        x1 = np.concatenate((np.power(x, 1 + d), x1), axis=1)\n",
        "    \n",
        "    # Generate target values: y = Xw + noise\n",
        "    y = np.dot(x1, w) + np.random.normal(size=(num_points,)) * noise\n",
        "\n",
        "    return x1, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef506902",
      "metadata": {},
      "source": [
        "#### Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f214b7c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_data(X: np.array, Y: np.array, fig=None, options: dict = dict())->None:\n",
        "    \"\"\"\n",
        "    Plot data points.\n",
        "    \n",
        "    Args:\n",
        "        X (np.array): Feature values for x-axis\n",
        "        Y (np.array): Values for y-axis\n",
        "        fig: Matplotlib figure object (optional)\n",
        "        options (dict): Plotting options including:\n",
        "            - marker: Point style (default: 'b*')\n",
        "            - label: Legend label (default: 'Raw data')\n",
        "            - fillstyle: Point fill style (default: 'full')\n",
        "            - size: Point size (default: 8)\n",
        "    \"\"\"\n",
        "    if fig is None:\n",
        "        fig = plt.subplot(111)\n",
        "    \n",
        "    # Plot data points with specified options\n",
        "    fig.plot(X, Y, \n",
        "            options.get('marker', 'b*'),        # Default: blue stars \n",
        "            label=options.get('label', 'Raw data'),\n",
        "            fillstyle=options.get('fillstyle', 'full'),\n",
        "            ms=options.get('size', 8))\n",
        "    \n",
        "    process_plot(fig, options)\n",
        "\n",
        "def plot_fit(X: np.array, w: np.array, fig=None, options: dict = dict())->None:\n",
        "    \"\"\"\n",
        "    Plot the polynomial regression fit line.\n",
        "    \n",
        "    Args:\n",
        "        X (np.array): Original feature matrix\n",
        "        w (np.array): Learned polynomial coefficients\n",
        "        fig: Matplotlib figure object (optional)\n",
        "        options (dict): Plotting options\n",
        "    \"\"\"\n",
        "    if fig is None:\n",
        "        fig = plt.subplot(111)\n",
        "\n",
        "    # Get range of x values to plot\n",
        "    x_min = np.min(X[:, -2])\n",
        "    x_max = np.max(X[:, -2])\n",
        "    dim = w.size - 1  # Polynomial degree\n",
        "    \n",
        "    # Generate smooth x values for plotting\n",
        "    x_plot = np.reshape(np.linspace(x_min, x_max, 100), [-1, 1])\n",
        "    x1_plot = np.ones_like(x_plot)  # Initialize with ones (bias term)\n",
        "    \n",
        "    # Generate polynomial features for plotting\n",
        "    for d in range(dim):\n",
        "        x1_plot = np.concatenate((np.power(x_plot, 1 + d), x1_plot), axis=1)\n",
        "\n",
        "    # Calculate predicted y values\n",
        "    y_plot = np.dot(x1_plot, w)\n",
        "    \n",
        "    # Plot regression line\n",
        "    fig.plot(x_plot, y_plot, 'r-', \n",
        "            label=options.get('label', 'Regression fit'))\n",
        "    \n",
        "    process_plot(fig, options)\n",
        "\n",
        "def process_plot(fig, options: dict = dict())->None:\n",
        "    \"\"\"\n",
        "    Apply common plotting options to figure.\n",
        "    \n",
        "    Args:\n",
        "        fig: Matplotlib figure object\n",
        "        options (dict): Dictionary of plotting options including:\n",
        "            - x_label: Label for x-axis\n",
        "            - y_label: Label for y-axis\n",
        "            - x_lim: Limits for x-axis\n",
        "            - y_lim: Limits for y-axis\n",
        "            - title: Plot title\n",
        "            - legend: Whether to show legend\n",
        "            - legend_loc: Legend location\n",
        "    \"\"\"\n",
        "    # Set axis labels\n",
        "    if 'x_label' in options.keys():\n",
        "        fig.set_xlabel(options['x_label'])\n",
        "    if 'y_label' in options.keys():\n",
        "        fig.set_ylabel(options['y_label'])\n",
        "    \n",
        "    # Set axis limits\n",
        "    if 'x_lim' in options.keys():\n",
        "        fig.set_ylim(options['x_lim'])\n",
        "    if 'y_lim' in options.keys():\n",
        "        fig.set_ylim(options['y_lim'])\n",
        "    \n",
        "    # Set title and legend\n",
        "    if 'title' in options.keys():\n",
        "        fig.set_title(options['title'])\n",
        "    if 'legend' in options.keys():\n",
        "        if options['legend']:\n",
        "            fig.legend(loc=options.get('legend_loc', 'best'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51001ec",
      "metadata": {},
      "source": [
        "### Usage Example\n",
        "Notes:\n",
        "- The `generate_polynomial_data` function creates synthetic data following y = w₁x + w₀ + noise\n",
        "- For reproducibility, we use a fixed random seed (42)\n",
        "- The plotting functions support customization through the options dictionary\n",
        "- These functions are designed to work with polynomial regression of any degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e0def2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic data\n",
        "num_points = 100\n",
        "noise = 0.6\n",
        "w_true = np.array([2, -2])  # Linear function: y = 2x -2\n",
        "X, y = generate_polynomial_data(num_points, noise, w_true)\n",
        "\n",
        "# Create plot\n",
        "fig = plt.subplot(111)\n",
        "plot_options = {\n",
        "    'x_label': 'x',\n",
        "    'y_label': 'y',\n",
        "    'title': 'Polynomial Regression Example',\n",
        "    'legend': True\n",
        "}\n",
        "\n",
        "# Plot data and fit\n",
        "plot_data(X[:, 0], y, fig=fig, options=plot_options)\n",
        "plot_fit(X, w_true, fig=fig, options=plot_options)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sMqfxOF-90Wn",
      "metadata": {
        "id": "sMqfxOF-90Wn"
      },
      "source": [
        "### Loading and Processing Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nbckc1W4-bGt",
      "metadata": {
        "id": "nbckc1W4-bGt"
      },
      "outputs": [],
      "source": [
        "def generate_and_plot_data(num_points: int, noise: float, w_true: np.array, test_size: float = 0.4, random_state: int = 42) -> Tuple[np.array, np.array, np.array, np.array]:\n",
        "    \"\"\"\n",
        "    Generate synthetic polynomial regression data, split into training and testing sets, and plot the data.\n",
        "    \n",
        "    Args:\n",
        "        num_points (int): Number of data points to generate\n",
        "        noise (float): Standard deviation of Gaussian noise\n",
        "        w_true (np.array): True polynomial coefficients [w_n, ..., w_1, w_0]\n",
        "        test_size (float): Proportion of the dataset to include in the test split\n",
        "        random_state (int): Random seed for reproducibility\n",
        "    \n",
        "    Returns:\n",
        "        X_train (np.array): Training feature matrix\n",
        "        X_test (np.array): Testing feature matrix\n",
        "        y_train (np.array): Training target values\n",
        "        y_test (np.array): Testing target values\n",
        "    \"\"\"\n",
        "    # Generate the data\n",
        "    X, y = generate_polynomial_data(num_points, noise, w_true)  # y = X w_true + noise\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Plot Data\n",
        "    fig = plt.subplot(111)\n",
        "    plot_opts = {'x_label': '$x$', 'y_label': '$y$', 'title': 'Generated Data', 'y_lim': [np.min(y) - 0.5, np.max(y) + 0.5]}\n",
        "    plot_data(X[:, 0], y, fig=fig, options=plot_opts)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Example usage\n",
        "num_points = 100  # Number of training points\n",
        "noise = 0.6  # Noise level\n",
        "w_true = np.array([2, 0.6])  # Ground truth function parameter\n",
        "\n",
        "X_train, X_test, y_train, y_test = generate_and_plot_data(num_points, noise, w_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b37dbbc",
      "metadata": {},
      "source": [
        "## Task 1A.1: Modeling (30 pts)\n",
        "\n",
        "In the following, you will write you own loss function for this linear regression task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QadXjQtrBHXR",
      "metadata": {
        "id": "QadXjQtrBHXR"
      },
      "source": [
        "### The key ingredient of modeling: Risk (i.e. expected loss) function and its gradient\n",
        "\n",
        "We will start by fitting by linear regression a set of data points of the type $\\left\\{(\\mathbf{x}, y)_i\\right\\}$, $i \\in \\{1, 2, \\ldots, n\\}$.\n",
        "\n",
        "The objective of linear regression, is to find coefficents $\\hat{\\mathbf{w}}$ such that the residual between $\\hat{y} = \\hat{\\mathbf{w}}^\\top \\tilde{\\mathbf{x}}$, and $y$ is small. (Remember that $\\tilde{\\mathbf{x}} = [\\mathbf{x}, 1]$). From now on, $\\mathbf{x}$ will be considered the extended version unless stated otherwise, hence dropping the tilde notation. \n",
        "\n",
        "We consider the ridge regression risk function, defined as \n",
        "$$ R({\\mathbf{w}}) = \\mathbb{E}[(y-{\\mathbf{w}}^\\top \\mathbf{x})^2)] +  \\lambda \\mathbf{w}^\\top \\mathbf{w}$$\n",
        "\n",
        "where the expectation is taken over the data generating the distribution of points. As the data generating distribution is not known, the expectation is approximated by samples from the **training** set. \n",
        "\n",
        "The risk is approximated by the *empirical risk* as:\n",
        "\n",
        "\n",
        "$$\\hat{R}_{\\text{ridge}}(\\mathbf{w}) = \\frac{1}{n} \\sum_{i=1}^n \\left(y_i - \\mathbf{w}^\\top \\mathbf{x}_i\\right)^2 + \\lambda \\mathbf{w}^\\top \\mathbf{w}$$\n",
        "\n",
        "In the following, construct a customized funciton which returns the empirical risk and its gradient at parameter $\\mathbf{w}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W7gfoERbCtRE",
      "metadata": {
        "id": "W7gfoERbCtRE"
      },
      "outputs": [],
      "source": [
        "# Constructing the empirical risk function for ridge regression.\n",
        "def lossFunction(w, X, y ,Lambda):\n",
        "    \"\"\"\n",
        "    Take in numpy array of w, X, and y to return the regularize loss function and gradient\n",
        "    of a logistic regression\n",
        "    \"\"\"\n",
        "    # initialize regularized average loss (empirical risk) and its gradient\n",
        "    regLoss = 0\n",
        "    grad = np.zeros(w.shape)\n",
        "\n",
        "    ##############################################################\n",
        "    # add your code to compute the ridge regression risk function and its gradient #\n",
        "    #\n",
        "    #\n",
        "    \n",
        "    \n",
        "    ##############################################################\n",
        "\n",
        "    return regLoss, grad\n",
        "\n",
        "# Initialize fitting parameters\n",
        "initial_w = np.zeros((X.shape[1], 1))\n",
        "\n",
        "# Set regularization parameter lambda\n",
        "Lambda = 0.01\n",
        "\n",
        "# Compute and display initial loss and gradient for regularized logistic regression\n",
        "emp_risk, grad=lossFunction(initial_w, X, y, Lambda)\n",
        "print(\"Loss at initial w (zeros):\",emp_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MxRzx3IrVrJ4",
      "metadata": {
        "id": "MxRzx3IrVrJ4"
      },
      "source": [
        "## Task 1A.2: Training Your Ridge Regressor: Gradient Descent (15 pts)\n",
        "\n",
        "There are many algorithmic tools for training your regressor. Here, we use the popular gradient descent algorithm.\n",
        "\n",
        "The parameters $\\hat{\\mathbf{w}}$ can be updated via a gradient descent rule: \n",
        "\n",
        "$$ \\hat{\\mathbf{w}}_{t+1} \\gets \\hat{\\mathbf{w}}_t - \\eta_t \\left.\\frac{\\partial \\hat{R}}{\\partial \\mathbf{w}} \\right|_{\\mathbf{w}=\\hat{\\mathbf{w}}_t},$$\n",
        "\n",
        "where $\\eta_t$ is a parameter of the algorithm, $t$ is the iteration index, and $\\frac{\\partial \\hat{R}}{\\partial \\mathbf{w}}$ is the gradient of the empirical risk function w.r.t. $\\mathbf{w}$.\n",
        "\n",
        "In the *vanilla* gradient descent method, $\\eta_t=\\eta_0$ is a constant. However other algorithms exists that modify this.\n",
        "\n",
        "The computational complexity of gradient descent is $O(n_{\\text{iter}} \\cdot  n d)$. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NrsxE-mPXUvB",
      "metadata": {
        "id": "NrsxE-mPXUvB"
      },
      "source": [
        "Write a customized function `gradientDescent(X,y,theta,eta,Lambda,tolerance)`\n",
        " which returns an array of empirical risk values, one for each iteration, as well as the final output of the model parameter. \n",
        " \n",
        " Here, `tollerance` specifies the stopping condition: The gradient descent algorithm terminates the observed loss values converges (i.e. two consective losses differ by at most `tollerance`). \n",
        "\n",
        " (*Hint: the loss should be descending in the loss plot.*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R1OdRyuoWgZg",
      "metadata": {
        "id": "R1OdRyuoWgZg"
      },
      "outputs": [],
      "source": [
        "def gradientDescent(X: np.array, y: np.array, w: np.array, eta: float, Lambda: float, tolerance: float) -> Tuple[np.array, list]:\n",
        "    \"\"\"\n",
        "    Perform gradient descent to minimize the loss function.\n",
        "    \n",
        "    Args:\n",
        "        X (np.array): Feature matrix\n",
        "        y (np.array): Target values\n",
        "        w (np.array): Initial coefficients\n",
        "        eta (float): Learning rate\n",
        "        Lambda (float): Regularization parameter\n",
        "        tolerance (float): Convergence tolerance\n",
        "    \n",
        "    Returns:\n",
        "        Tuple[np.array, list]: Final coefficients and loss history\n",
        "    \"\"\"\n",
        "    Loss_history = []\n",
        "    m = len(y)\n",
        "    prev_loss = np.inf\n",
        "    \n",
        "    ##############################################################\n",
        "    # add your code to compute the output of the gradient, as well as the loss histroy #\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    \n",
        "    ##############################################################\n",
        "    \n",
        "    return w, Loss_history\n",
        "\n",
        "# Parameters\n",
        "Eta = 0.1\n",
        "Tolerance = 1e-6\n",
        "\n",
        "\n",
        "# Perform gradient descent\n",
        "w, Loss_history = gradientDescent(X_train, y_train, initial_w, Eta, Lambda, Tolerance)\n",
        "print(\"The regularized w using ridge regression:\\n\", w)\n",
        "\n",
        "# Plot loss history\n",
        "plt.plot(Loss_history)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"$Loss(w)$\")\n",
        "plt.title(\"Loss function using Gradient Descent\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wwWnkqDVeD9n",
      "metadata": {
        "id": "wwWnkqDVeD9n"
      },
      "source": [
        "## Task 1A.3: Test Module (5 pts)\n",
        "\n",
        "We still need a method to evaluate the model constructed. Here, we plot the predicted values on the test data, together with the training points.\n",
        "\n",
        "You can plot the final results with the following script. Include the results in your project report and briefly (in 2~3 sentences) explain your observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YfSEpgt7eMsE",
      "metadata": {
        "id": "YfSEpgt7eMsE"
      },
      "outputs": [],
      "source": [
        "# Plot predicted function\n",
        "fig = plt.subplot(111)\n",
        "plot_opts = {'x_label': '$x$', 'y_label': '$y$', 'title': 'Ridge Regression', 'legend': True,\n",
        "                 'y_lim': [np.min(y)-0.5, np.max(y)+0.5]}\n",
        "\n",
        "plot_data(X_train[:,0], y_train, fig=fig, options=plot_opts)\n",
        "plot_fit(X_test, w, fig=fig, options=plot_opts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39eaf4bc",
      "metadata": {},
      "source": [
        "## [Bonus] Task 1A.4: True Risk (10 pts)\n",
        "\n",
        "In this task, you will compute the expected error (true risk) of your model, and answer a few questions related to model selection based on your observations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad53e71",
      "metadata": {},
      "source": [
        "### 1A.4.1 Estimation of Expected Error for Linear Regressor (6 pts)\n",
        "\n",
        "In this task, you will compute and compare the expected error and estimated error of your trained model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e55a6c6a",
      "metadata": {},
      "source": [
        "**Direct Estimation (Students' Task):**\n",
        "\n",
        "We first give a brief overview of the estimation of the model's expected error, and some factors related to the model consistency.\n",
        "\n",
        "The true risk for our linear regression model can be directly computed since we know:\n",
        "- Input $\\mathbf{x} = [x_0, 1]^\\top$ is sampled from standard normal distribution where $x_0 \\sim \\mathcal{N}(0,1)$\n",
        "- True parameter is $\\mathbf{w}_\\text{true} = [2, -2]^T$\n",
        "- Noise follows $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ where $\\sigma = 0.6$\n",
        "\n",
        "For a learned parameter $\\hat{\\mathbf{w}}$, the true error given MSE as the loss function is:\n",
        "\n",
        "\\begin{align}\n",
        "E(\\hat{\\mathbf{w}}) &= \\mathbb{E}_\\mathbf{x}[(\\mathbf{w}_\\text{true}^\\top \\mathbf{x} + \\epsilon - \\hat{\\mathbf{w}}^\\top \\mathbf{x})^2] \\\\\n",
        "\n",
        "&= \\mathbb{E}_\\mathbf{x}[(\\mathbf{w}_\\text{true}^\\top \\mathbf{x} - \\hat{\\mathbf{w}}^\\top \\mathbf{x})^2] + \\mathbb{E}[\\epsilon^2] \\\\\n",
        "\n",
        "&= (\\mathbf{w}_\\text{true} - \\hat{\\mathbf{w}})^\\top \\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top](\\mathbf{w}_\\text{true} - \\hat{\\mathbf{w}}) + \\sigma^2 \\\\\n",
        "\n",
        "&= (\\mathbf{w}_\\text{true} - \\hat{\\mathbf{w}})^\\top I(\\mathbf{w}_\\text{true} - \\hat{\\mathbf{w}}) + \\sigma^2 \\\\\n",
        "\n",
        "&= \\|\\mathbf{w}_\\text{true} - \\hat{\\mathbf{w}}\\|_2^2 + \\sigma^2\n",
        "\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "where we used:\n",
        "- $\\mathbb{E}[\\mathbf{x}\\mathbf{x}^T] = I$ (for $x_0 \\sim \\mathcal{N}(0,1)$)\n",
        "- $\\mathbb{E}[\\epsilon^2] = \\sigma^2$\n",
        "- Independence of $\\mathbf{x}$ and $\\epsilon$\n",
        "\n",
        "**K-fold Cross-validation:**\n",
        "\n",
        "We can compare this theoretical expected error with estimates from $k$-fold cross-validation:\n",
        "\n",
        "$$\\hat{E}(\\hat{\\mathbf{w}}) = \\frac{1}{k} \\sum_{i=1}^k \\left[ \\frac{1}{|V_i|} \\sum_{(\\mathbf{x},y)\\in V_i} (y - \\hat{\\mathbf{w}}_i^\\top \\mathbf{x})^2 \\right]$$\n",
        "\n",
        "where\n",
        "- $k$ is the number of folds\n",
        "- $V_i$ is the validation set ($i$-th fold)\n",
        "- $\\hat{\\mathbf{w}}_i$ is the model trained on all folds except $V_i$\n",
        "- $|V_i|$ is the size of the validation fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f7ec7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Students Code for this function\n",
        "def true_gen_error(w: np.array, w_true: np.array = np.array([2, 0.6]), sigma: float = 0.6) -> float:\n",
        "    \"\"\"\n",
        "    Calculate true expected error.\n",
        "    \n",
        "    Args:\n",
        "        w (np.array): Learned polynomial coefficients\n",
        "        w_true (np.array): True polynomial coefficients\n",
        "        sigma (float): Standard deviation of Gaussian noise\n",
        "    \n",
        "    Returns:\n",
        "        float: True risk\n",
        "    \"\"\"\n",
        "    error = 0\n",
        "    ##############################################################\n",
        "    # please add your code here to compute the expected error (true risk)\n",
        "    #\n",
        "    #\n",
        "\n",
        "\n",
        "    ##############################################################\n",
        "    \n",
        "    return error\n",
        "\n",
        "# In this section we directly call CV from sklearn\n",
        "def estimate_gen_error_cv(X: np.array, y: np.array, k: int = 5) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Estimate expected error using k-fold cross-validation.\n",
        "    \n",
        "    Args:\n",
        "        X (np.array): Feature matrix\n",
        "        y (np.array): Target values\n",
        "        k (int): Number of folds for cross-validation\n",
        "    \n",
        "    Returns:\n",
        "        Tuple[float, float]: Mean and standard deviation of the estimated expected error\n",
        "    \"\"\"\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    errors = []\n",
        "    \n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        # Split data into training and validation\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "        \n",
        "        # Train model\n",
        "        initial_w = np.zeros((X_train.shape[1], 1))\n",
        "        w, _ = gradientDescent(X_train, y_train, initial_w, 0.01, 0.1, 1e-6)\n",
        "        \n",
        "        # Calculate MSE on validation set\n",
        "        y_pred = X_val.dot(w)\n",
        "        mse = mean_squared_error(y_val, y_pred)\n",
        "        errors.append(mse)\n",
        "    \n",
        "    return np.mean(errors), np.std(errors)\n",
        "\n",
        "# Compare theoretical and estimated errors\n",
        "w_learned, _ = gradientDescent(X_train, y_train, np.zeros((2, 1)), 0.01, 0.1, 1e-6)\n",
        "true_error = true_gen_error(w_learned)\n",
        "cv_error, cv_std = estimate_gen_error_cv(X_train, y_train)\n",
        "\n",
        "print(f\"True expected error: {true_error:.4f}\")\n",
        "print(f\"5-fold CV estimate: {cv_error:.4f} (±{cv_std:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f28f582",
      "metadata": {},
      "source": [
        "### 1A.4.2 Convergence of Expected Error (4 pts)\n",
        "\n",
        "As discussed by Vladimir Vapnik in his foundation laying work *The Nature of Statistical Learning Theory* (Springer, 1995), learning theory must address four principal questions:\n",
        "\n",
        "1. *What are the (necessary and sufficient) conditions for consistency of a learning process based on the Empirical Risk Minimization (ERM) principle?*  \n",
        "2. ***How fast is the rate of convergence of the learning process?***\n",
        "3. *How can one control the rate of convergence (the generalization ability) of the learning process?*  \n",
        "4. *How can one construct algorithms that can control the generalization ability?*\n",
        "\n",
        "When we focus on the second question—namely, the rate of convergence of the learning process—and how various factors affect the **expected error**. Key considerations include:\n",
        "\n",
        "- **Distribution mismatch**: Differences between the training data generation distribution and the “true” (or test) distribution, often quantified through divergences such as KL divergence.  \n",
        "- **Number of training samples**: Larger datasets typically lead to faster convergence rates under mild assumptions about the data-generating process.  \n",
        "- **Model complexity**: More complex hypothesis classes may require stronger regularization or more data to achieve comparable convergence.  \n",
        "- **Observation noise**: Higher noise levels can slow convergence by obscuring the true signal and increasing variance in parameter estimates.\n",
        "\n",
        "In what follows, we briefly highlight the role of observation noise in shaping the convergence rate of the expected error in empirical study. We will see that increasing noise typically inflates error bounds and slows down the overall convergence, further underscoring the importance of careful model selection and noise-robust learning algorithms.\n",
        "\n",
        "**Your task is to implement the naive linear regression in the corresponding part, and answer the following questions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10e34b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_noise_impact(noise_levels: list = [0.9, 1.2, 1.5, 1.8, 2.1, 2.4], \n",
        "                         sample_sizes: np.array = np.linspace(10, 30, 6, dtype=int),\n",
        "                         w_true: np.array = np.array([2, 0.6]),\n",
        "                         n_repeats: int = 10) -> None:\n",
        "    \"\"\"\n",
        "    Analyze impact of observation noise on expected error convergence.\n",
        "    \n",
        "    Args:\n",
        "        noise_levels (list): Different noise levels to test\n",
        "        sample_sizes (np.array): Different sample sizes to test\n",
        "        w_true (np.array): True polynomial coefficients\n",
        "        n_repeats (int): Number of repetitions for each configuration\n",
        "    \"\"\"\n",
        "    # Store results\n",
        "    true_errors = {noise: np.zeros((len(sample_sizes), n_repeats)) for noise in noise_levels}\n",
        "    cv_errors = {noise: np.zeros((len(sample_sizes), n_repeats)) for noise in noise_levels}\n",
        "    cv_stds = {noise: np.zeros((len(sample_sizes), n_repeats)) for noise in noise_levels}\n",
        "\n",
        "    # Store results for naive linear regression\n",
        "    naive_true_errors = {noise: np.zeros((len(sample_sizes), n_repeats)) for noise in noise_levels}\n",
        "    naive_cv_errors = {noise: np.zeros((len(sample_sizes), n_repeats)) for noise in noise_levels}\n",
        "    naive_cv_stds = {noise: np.zeros((len(sample_sizes), n_repeats)) for noise in noise_levels}\n",
        "    \n",
        "    def fit_naive_linear_regression(X: np.array, y: np.array) -> np.array:\n",
        "        \"\"\"Fit linear regression using normal equations\"\"\"\n",
        "        w = np.zeros((X.shape[1], 1))\n",
        "        ##############################################################\n",
        "        # please add your code here to fit the linear regression without regularization\n",
        "        # the answer should return the learned weight vector given training data X and y\n",
        "        #\n",
        "        #\n",
        "        \n",
        "        \n",
        "        ##############################################################\n",
        "        \n",
        "        return w\n",
        "    \n",
        "    def estimate_naive_gen_error_cv(X: np.array, y: np.array, k: int = 5) -> Tuple[float, float]:\n",
        "        \"\"\"Estimate expected error for naive linear regression using k-fold CV\"\"\"\n",
        "        kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "        errors = []\n",
        "        \n",
        "        for train_idx, val_idx in kf.split(X):\n",
        "            X_train, X_val = X[train_idx], X[val_idx]\n",
        "            y_train, y_val = y[train_idx], y[val_idx]\n",
        "            \n",
        "            w = fit_naive_linear_regression(X_train, y_train)\n",
        "            y_pred = X_val @ w\n",
        "            mse = mean_squared_error(y_val, y_pred)\n",
        "            errors.append(mse)\n",
        "        \n",
        "        return np.mean(errors), np.std(errors)\n",
        "    \n",
        "    # Run experiments\n",
        "    for noise in noise_levels:\n",
        "        print(f\"Processing noise level: {noise}\")\n",
        "        for i, n_samples in enumerate(sample_sizes):\n",
        "            for j in range(n_repeats):\n",
        "                # Generate data\n",
        "                X_train, X_test, y_train, y_test = generate_and_plot_data(\n",
        "                    n_samples, noise, w_true, test_size=0.2)\n",
        "                \n",
        "                # Train model\n",
        "                w_init = np.zeros((X_train.shape[1], 1))\n",
        "                w_learned, _ = gradientDescent(X_train, y_train, w_init, 0.001, 0.1, 1e-6)\n",
        "                \n",
        "                # Calculate true expected error\n",
        "                true_errors[noise][i, j] = true_gen_error(w_learned, w_true, noise)\n",
        "                \n",
        "                # Estimate expected error using cross-validation\n",
        "                cv_error, cv_std = estimate_gen_error_cv(X_train, y_train)\n",
        "                cv_errors[noise][i, j] = cv_error\n",
        "                cv_stds[noise][i, j] = cv_std\n",
        "\n",
        "                # Naive linear regression\n",
        "                w_naive = fit_naive_linear_regression(X_train, y_train)\n",
        "                naive_true_errors[noise][i, j] = true_gen_error(w_naive, w_true, noise)\n",
        "                naive_cv_error, naive_cv_std = estimate_naive_gen_error_cv(X_train, y_train)\n",
        "                naive_cv_errors[noise][i, j] = naive_cv_error\n",
        "                naive_cv_stds[noise][i, j] = naive_cv_std\n",
        "    \n",
        "    # Plot results\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    # Plot true expected error for ridge regression\n",
        "    plt.subplot(231)\n",
        "    for noise in noise_levels:\n",
        "        mean_error = np.mean(true_errors[noise], axis=1)\n",
        "        std_error = np.std(true_errors[noise], axis=1)\n",
        "        \n",
        "        plt.plot(sample_sizes, mean_error, label=f'σ={noise}', marker='o')\n",
        "        plt.fill_between(sample_sizes, mean_error - std_error, mean_error + std_error, alpha=0.2)\n",
        "    \n",
        "    plt.xlabel('Number of Training Samples')\n",
        "    plt.ylabel('True Expected Error')\n",
        "    plt.title('Ridge Regression: True Expected Error')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # Plot CV estimated error for ridge regression\n",
        "    plt.subplot(232)\n",
        "    for noise in noise_levels:\n",
        "        mean_error = np.mean(cv_errors[noise], axis=1)\n",
        "        mean_std = np.mean(cv_stds[noise], axis=1)\n",
        "        \n",
        "        plt.plot(sample_sizes, mean_error, label=f'σ={noise}', marker='o')\n",
        "        plt.fill_between(sample_sizes, mean_error - mean_std, mean_error + mean_std, alpha=0.2)\n",
        "    \n",
        "    plt.xlabel('Number of Training Samples')\n",
        "    plt.ylabel('CV Estimated Error')\n",
        "    plt.title('Ridge Regression: CV Est. Error')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot ratio of true/CV error for ridge regression\n",
        "    plt.subplot(233)\n",
        "    for noise in noise_levels:\n",
        "        mean_true = np.mean(true_errors[noise], axis=1)\n",
        "        mean_cv = np.mean(cv_errors[noise], axis=1)\n",
        "        ratio = mean_true / mean_cv\n",
        "        \n",
        "        plt.plot(sample_sizes, ratio, label=f'σ={noise}', marker='o')\n",
        "    \n",
        "    plt.axhline(y=1, color='k', linestyle='--', alpha=0.3)\n",
        "    plt.xlabel('Number of Training Samples')\n",
        "    plt.ylabel('True/CV Error Ratio')\n",
        "    plt.title('Ridge Regression: Error Ratio')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot true expected error for naive regression\n",
        "    plt.subplot(234)\n",
        "    for noise in noise_levels:\n",
        "        mean_error = np.mean(naive_true_errors[noise], axis=1)\n",
        "        std_error = np.std(naive_true_errors[noise], axis=1)\n",
        "        \n",
        "        plt.plot(sample_sizes, mean_error, label=f'σ={noise}', marker='o')\n",
        "        plt.fill_between(sample_sizes, mean_error - std_error, mean_error + std_error, alpha=0.2)\n",
        "    \n",
        "    plt.xlabel('Number of Training Samples')\n",
        "    plt.ylabel('True Expected Error')\n",
        "    plt.title('Naive Regression: True Expected Error')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot CV estimated error for naive regression\n",
        "    plt.subplot(235)\n",
        "    for noise in noise_levels:\n",
        "        mean_error = np.mean(naive_cv_errors[noise], axis=1)\n",
        "        mean_std = np.mean(naive_cv_stds[noise], axis=1)\n",
        "        \n",
        "        plt.plot(sample_sizes, mean_error, label=f'σ={noise}', marker='o')\n",
        "        plt.fill_between(sample_sizes, mean_error - mean_std, mean_error + mean_std, alpha=0.2)\n",
        "    \n",
        "    plt.xlabel('Number of Training Samples')\n",
        "    plt.ylabel('CV Estimated Error')\n",
        "    plt.title('Naive Regression: CV Est. Error')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # Plot ratio of true/CV error for naive regression\n",
        "    plt.subplot(236)\n",
        "    for noise in noise_levels:\n",
        "        mean_true = np.mean(naive_true_errors[noise], axis=1)\n",
        "        mean_cv = np.mean(naive_cv_errors[noise], axis=1)\n",
        "        ratio = mean_true / mean_cv\n",
        "        \n",
        "        plt.plot(sample_sizes, ratio, label=f'σ={noise}', marker='o')\n",
        "    \n",
        "    plt.axhline(y=1, color='k', linestyle='--', alpha=0.3)\n",
        "    plt.xlabel('Number of Training Samples')\n",
        "    plt.ylabel('True/CV Error Ratio')\n",
        "    plt.title('Naive Regression: Error Ratio')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run the analysis\n",
        "analyze_noise_impact()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "471330cb",
      "metadata": {},
      "source": [
        "#### Questions\n",
        "Please discuss your findings by addressing the following questions.\n",
        "\n",
        "- How does observation noise affect generalization performance?\n",
        "- Under what conditions is ridge regression meaningful, and when does naïve linear regression lead to overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WtqtDFrS1w6Y",
      "metadata": {
        "id": "WtqtDFrS1w6Y"
      },
      "source": [
        "# Task 1B: Model Selection for House Value Prediction (50 points)\n",
        "\n",
        "We will use the [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from the scikit-learn package. The task is to predict the house values in California districts given some summary stats about them based on the 1990 census data.\n",
        "\n",
        "The dataset has 8 features: longitudes, latitudes, housing median age, total rooms, total bedrooms, population, households, median income, and median house value. The target variable is the median house value for California districts, expressed in hundreds of thousands of dollars ($\\$100,000$). We split the dataset as 80\\% for training data and 20\\% for testing data. \n",
        "\n",
        "The following script loads the dataset (using pandas dataframe):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WxDckRfM4Ac_",
      "metadata": {
        "id": "WxDckRfM4Ac_"
      },
      "outputs": [],
      "source": [
        "# python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "\n",
        "california=fetch_california_housing()\n",
        "california_df=pd.DataFrame(california.data,columns=california.feature_names)\n",
        "california_df['Price']=california.target\n",
        "california_df \n",
        "\n",
        "newX=california_df.drop('Price',axis=1)\n",
        "newY=california_df['Price']\n",
        "\n",
        "newX = StandardScaler().fit_transform(newX)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1354dfd6",
      "metadata": {},
      "source": [
        "## Task 1B.1: Ridge Regression (30 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OdD-ghQfqpN-",
      "metadata": {
        "id": "OdD-ghQfqpN-"
      },
      "source": [
        "\n",
        "Following the script below, you will be able to generate the training and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374bab52",
      "metadata": {
        "id": "374bab52"
      },
      "outputs": [],
      "source": [
        "N_train = len(newX) * .8\n",
        "\n",
        "np.random.seed(150)\n",
        "msk = np.random.rand(len(newX)) < 0.8\n",
        "\n",
        "X_train, y_train = newX[msk], newY[msk]\n",
        "X_test, y_test = newX[~msk], newY[~msk]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7CCr2O23sHNq",
      "metadata": {
        "id": "7CCr2O23sHNq"
      },
      "source": [
        "### Training and evaluation (15 pts)\n",
        "\n",
        "Write a function to fit the Ridge regression model on the training data and calculate the MSE on the test set. Choosing $\\lambda$ from $\\{10^{-10}, 10^{-6}, 10^{-4}, 10^{-2}, 10^{-1}, 1, 10, 20, 50, 100\\}$, compute the estimate $\\hat{\\mathbf{y}}$ for different values $\\lambda$, and plot the test MSE as a function of $\\lambda$. \n",
        "\n",
        "\n",
        "❗**Note**: You should use your own model fitting and prediction (following the ones you construct in Task 1A). You may call your customized function `lossFunction` and `gradientDescent` from Task 1A.1 and 1A.2. Do not use `sklearn.linear_model` module (i.e. for model fitting and making predictions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54cdd721",
      "metadata": {
        "id": "54cdd721"
      },
      "outputs": [],
      "source": [
        "def train_and_eval( X_train , y_train , X_eval , y_eval , lambda_ ):\n",
        "  \n",
        "    mse = 0\n",
        "    # Initialize weight\n",
        "    initial_w = np.zeros((X_train.shape[1], 1))\n",
        "\n",
        "    ##############################################################\n",
        "    # add your code to train your model on X_train and evalute (i.e. computing MSE) on X_eval. \n",
        "    # For gradientDescent, you may try the following configuration for comparison with later sections\n",
        "    #   Eta = 0.01, Tolerance = 1e-4, max_iter=1e4\n",
        "    # but feel free to experiment.\n",
        "    #\n",
        "    \n",
        "    \n",
        "    # Make predictions on the evaluation set\n",
        "    #\n",
        "    ##############################################################\n",
        "    \n",
        "    return mse\n",
        "\n",
        "\n",
        "weight_list = [1e-10, 1e-6, 1e-4, 0.01, 0.1, 1, 10, 20, 50, 100]\n",
        "result_list = []\n",
        "\n",
        "# compute test MSE\n",
        "for weight in weight_list:\n",
        "    test_mse = train_and_eval ( X_train , y_train.values , X_test , y_test.values , weight )\n",
        "    result_list.append ([ test_mse , weight ])\n",
        "    result_array = np.array ( result_list )\n",
        "print(result_array)\n",
        "plt.figure()\n",
        "plt.plot( result_array [: , -1] , result_array [: ,0] , label = 'test mse')\n",
        "plt.xlabel('lambda')\n",
        "plt.ylabel('test mse')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa5319c",
      "metadata": {},
      "source": [
        "#### Questions\n",
        "- Suppose you found above that the optimal $\\lambda$ was very close to 0. Does this necessarily mean that Ridge regression is not helpful for this dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "__Sith5GtlSC",
      "metadata": {
        "id": "__Sith5GtlSC"
      },
      "source": [
        "### Model Selection via k-fold Cross Validation (15 pts)\n",
        "\n",
        "Implement *10-fold cross validation* on the training set to select $\\lambda$. \n",
        "\n",
        "❗**Note:** For this subproblem, you should write your own function for cross validation; in particular, you should **not** call the existing `sklearn.model_selection` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "809941e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_validation(X_train, y_train, lambda_, k=10):\n",
        "    \"\"\"\n",
        "    Perform k-fold cross validation on X_train and y_train, return the mean square error on the test portion of (X_train,y_train) across the k folds\n",
        "    \"\"\"\n",
        "    mse_list = []\n",
        "    \n",
        "    ##############################################################\n",
        "    # add your code to perform k-fold cross validation\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    \n",
        "    return np.mean(mse_list)\n",
        "\n",
        "\n",
        "# List of lambdas to try\n",
        "weight_list = [1e-10, 1e-6, 1e-4, 0.01, 0.1, 1, 10, 20, 50, 100]\n",
        "\n",
        "best_lambda = None\n",
        "best_mse = np.inf\n",
        "\n",
        "# Find the best lambda\n",
        "mse_list = []\n",
        "for lambda_ in weight_list:\n",
        "    print(\"cross validation with lambda: \", lambda_)\n",
        "    \n",
        "    ##############################################################\n",
        "    # mse on the hold-out set\n",
        "    cv_mse = cross_validation(X_train, y_train.values, lambda_)\n",
        "    mse_list.append(cv_mse)\n",
        "    if cv_mse < best_mse:\n",
        "        best_mse = cv_mse\n",
        "        best_lambda = lambda_\n",
        "\n",
        "print(\"Best lambda: \", best_lambda)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e4e199",
      "metadata": {},
      "source": [
        "Plot and compare the **(average) cross validation MSE** on the hold-out folds (i.e., test portion in each of the $k$ folds) with the **test MSE** which is computed on the test set (X_test, y_test). And see how we get to finding the ``best'' $\\lambda$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6b7892",
      "metadata": {},
      "source": [
        "#### Questions\n",
        "- Compare the model selection strategy used in vanilla ridge regression (i.e., on a single train/test split) and in $k$-fold cross validation. What are the pros and cons of each approach.\n",
        "- Suppose the best $\\lambda$ chosen by 10-fold cross-validation is significantly different from the best $\\lambda$ you found using vanilla Ridge Regression. Which value would you trust more, and why? What are some potential reasons for this discrepancy?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cd1dd07",
      "metadata": {},
      "source": [
        "## Task 1B.2: Polynomial Model Selection (20 pts)\n",
        "\n",
        "In this question, you will perform polynomial regression on the California housing dataset, and use cross-validation to determine the optimal degree of polynomial. For simplicity, we will use **a subset of the longitudes feature** and study its relationship with housing prices. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b8bd141",
      "metadata": {},
      "source": [
        "Following the previous notation, we consider the mean square risk function, defined as $$ R({\\mathbf{w}}) = \\mathbb{E}[(y-{\\mathbf{w}}^\\top \\mathbf{x})^2)].$$ For a polynomial regression of degree $D$, this becomes $$ R({\\mathbf{w}}) = \\mathbb{E}[(y-\\sum_{d = 1}^{D}w_d x^d)^2)] = \\mathbb{E}[(y-{\\mathbf{w}}^\\top \\mathbf{x})^2],$$ where the expectations are taken over the data generating the distribution of points. As the whole data generating distribution is not known, the expectation is approximated by samples from the **training** set. \n",
        "\n",
        "The risk is approximated by the *empirical risk* as: $$\\hat{R}_{\\text{MSE}}(\\mathbf{w}) = \\frac{1}{n} \\sum_{i=1}^n \\left(y_i - \\sum_{d = 1}^{D}w_d x_i^d\\right)^2.$$\n",
        "\n",
        "In the following, you will use gradient descent to find the the optimal $\\mathbf{w}$ for a given $D$ based on the MSE loss, and implement a cross validation function that performs $10$-fold cross validation to determine the optimal $D$ to fit this set of data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40646df3",
      "metadata": {},
      "source": [
        "Following the script below, you will be able to generate the training data. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d973bc8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# load data\n",
        "i= 45\n",
        "num_data = 200\n",
        "X_train = newX[i*num_data:(i+1)*num_data, 0]\n",
        "y_train = np.array(newY[i*num_data:(i+1)*num_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a9e5229",
      "metadata": {},
      "source": [
        "You may create your customized function `lossFunctionMSE` and `gradientDescentMSE` by modifying the corresponding functions from the previous tasks to adapt to the MSE loss and its gradient. You also need to adapt your `cross_validation` function below to handle the varying degrees $D$. A sample plotting command has been provided. You should create other plots as you deem necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a671dfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constructing the empirical risk function for MSE regression.\n",
        "def lossFunctionMSE(w, X, y):\n",
        "    \"\"\"\n",
        "    Take in numpy array of theta, X, and y to return the regularize loss function and gradient\n",
        "    of the mean square error function\n",
        "    \"\"\"\n",
        "    \n",
        "    # initialize mse loss and its gradient\n",
        "    loss = 0\n",
        "    grad = np.zeros(w.shape)\n",
        "\n",
        "    ##############################################################\n",
        "    # add your code to compute the MSE risk function and its gradient\n",
        "    #\n",
        "    #\n",
        "    \n",
        "    ##############################################################\n",
        "    \n",
        "    return loss, grad\n",
        "\n",
        "\n",
        "def gradientDescentMSE(X,y,w,eta,tolerance,max_iter=1000):\n",
        "    \"\"\"\n",
        "    Take in numpy array X, y and w and update w by taking num_iters gradient steps\n",
        "    with learning rate of eta\n",
        "    \n",
        "    return w and the list of the loss of w during each iteration\n",
        "    \"\"\"\n",
        "    ##############################################################\n",
        "    # add your code to perform gradient updates\n",
        "    #\n",
        "    #\n",
        "    \n",
        "    ##############################################################\n",
        "    \n",
        "    \n",
        "    return w, Loss_history\n",
        "\n",
        "\n",
        "def train_and_eval_dim( X_train , y_train , X_eval , y_eval , dim):\n",
        "  \n",
        "    mse = 0\n",
        "    # Initialize weight\n",
        "    initial_w = np.zeros((X_train.shape[1], 1))\n",
        "\n",
        "    ##############################################################\n",
        "    # add your code to train your model on X_train and evalute (i.e. computing MSE) on X_eval\n",
        "    # Train the model\n",
        "    #\n",
        "    \n",
        "    # Make predictions on the evaluation set\n",
        "    #\n",
        "    \n",
        "    \n",
        "    ##############################################################\n",
        "    \n",
        "    return mse\n",
        "\n",
        "def cross_validation_dim(X_train, y_train, dim, k=10):\n",
        "    \"\"\"\n",
        "    Perform k-fold cross validation on X_train and y_train\n",
        "    \n",
        "    return the mean square error on the test portion across the k folds\n",
        "    \"\"\"\n",
        "    \n",
        "    ##############################################################\n",
        "    # add your code to perform k-fold cross validation on the degree parameter dim\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    \n",
        "    ##############################################################\n",
        "    \n",
        "    return np.mean(mse_list)\n",
        "\n",
        "\n",
        "# List of candidate degrees \n",
        "degree_list = np.linspace(0, 4, 5, dtype=int)\n",
        "\n",
        "# Find the best degree\n",
        "result_list = []\n",
        "for degree in degree_list:\n",
        "    print(degree)\n",
        "    cv_mse = cross_validation_dim(X_train, y_train, degree)\n",
        "    result_list.append ([ cv_mse , degree ])\n",
        "result_array = np.array ( result_list )\n",
        "\n",
        "plt.figure()\n",
        "plt.plot( result_array [: , -1] , result_array [: ,0] , label = 'CV mse')\n",
        "plt.xlabel('degree of polynomial')\n",
        "plt.ylabel('mse')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca5c62e1",
      "metadata": {},
      "source": [
        "#### Questions\n",
        "- How would you use this information to determine the degree of polynomial you will use to represent this dataset?\n",
        "- Plot and analyze how the increasing degree of the polynomial change the training and validation loss. Do they change in different ways?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ml-course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
